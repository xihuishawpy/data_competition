{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 温室温度预测挑战赛\n",
    "http://challenge.xfyun.cn/topic/info?type=temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train/train.csv') # 3月14~4月3日 前20天\n",
    "test_df = pd.read_csv('./test/test.csv')  # 后十天"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time     年  月   日  小时  分钟   秒  温度(室外)  湿度(室外)  气压(室外)  湿度(室内)  \\\n",
      "0  1552496443  2019  3  14   1   0  43    14.6    85.0   993.1    80.0   \n",
      "1  1552496503  2019  3  14   1   1  43    14.7    84.0   993.0    80.0   \n",
      "2  1552496565  2019  3  14   1   2  45    14.7    84.0   992.7    80.0   \n",
      "3  1552496624  2019  3  14   1   3  44    14.6    85.0   993.2    80.0   \n",
      "4  1552496682  2019  3  14   1   4  42    14.6    85.0   992.7    80.0   \n",
      "\n",
      "   气压(室内)  temperature  \n",
      "0   992.4         15.4  \n",
      "1   992.6         15.4  \n",
      "2   992.8         15.4  \n",
      "3   992.6         15.4  \n",
      "4   992.6         15.3  \n",
      "(25497, 13),(406, 12)\n",
      "time             0\n",
      "年                0\n",
      "月                0\n",
      "日                0\n",
      "小时               0\n",
      "分钟               0\n",
      "秒                0\n",
      "温度(室外)         660\n",
      "湿度(室外)         660\n",
      "气压(室外)         660\n",
      "湿度(室内)         690\n",
      "气压(室内)         690\n",
      "temperature    690\n",
      "dtype: int64 time           0\n",
      "年              0\n",
      "月              0\n",
      "日              0\n",
      "小时             0\n",
      "分钟             0\n",
      "秒              0\n",
      "温度(室外)         2\n",
      "湿度(室外)         2\n",
      "气压(室外)         2\n",
      "湿度(室内)         1\n",
      "temperature    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(\"{},{}\".format(train_df.shape,test_df.shape))\n",
    "print(train_df.isnull().sum(),test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、把label非空的行作为训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['temperature'] 非空的行 \n",
    "train_df = train_df[train_df['temperature'].notnull()]\n",
    "\n",
    "# 其余空值，backfill/bfill：用下一个非缺失值填充该缺失值\n",
    "train_df = train_df.fillna(method='bfill')\n",
    "test_df = test_df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = ['time', 'year', 'month', 'day', 'hour', 'min', 'sec', 'outdoorTemp', 'outdoorHum', 'outdoorAtmo',\n",
    "                    'indoorHum', 'indoorAtmo', 'temperature']\n",
    "test_df.columns = ['time', 'year', 'month', 'day', 'hour', 'min', 'sec', 'outdoorTemp', 'outdoorHum', 'outdoorAtmo',\n",
    "                   'indoorHum', 'indoorAtmo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 74.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# 基本聚合特征\n",
    "group_feats = []\n",
    "for f in tqdm(['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']):\n",
    "    data_df['MDH_{}_medi'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('median')\n",
    "    data_df['MDH_{}_mean'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('mean')\n",
    "    data_df['MDH_{}_max'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('max')\n",
    "    data_df['MDH_{}_min'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('min')\n",
    "    data_df['MDH_{}_std'.format(f)] = data_df.groupby(['month', 'day', 'hour'])[f].transform('std')\n",
    "\n",
    "    group_feats.append('MDH_{}_medi'.format(f))\n",
    "    group_feats.append('MDH_{}_mean'.format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 487.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# 基本交叉特征\n",
    "for f1 in tqdm(['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo'] + group_feats):\n",
    "\n",
    "    for f2 in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo'] + group_feats:\n",
    "        if f1 != f2:\n",
    "            colname = '{}_{}_ratio'.format(f1, f2)\n",
    "            data_df[colname] = data_df[f1].values / data_df[f2].values\n",
    "            \n",
    "\n",
    "data_df = data_df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 57.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 56.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 62.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 62.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 62.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 61.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# 历史信息提取\n",
    "\n",
    "# 从3月至今的天数 \n",
    "data_df['dt'] = data_df['day'].values + (data_df['month'].values - 3) * 31\n",
    "\n",
    "for f in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo', 'temperature']:\n",
    "    tmp_df = pd.DataFrame()\n",
    "    for t in tqdm(range(15, 45)):\n",
    "        # 前 t天，按 hour 聚合指标（mean）\n",
    "        tmp = data_df[data_df['dt'] < t].groupby(['hour'])[f].agg({'mean'}).reset_index()\n",
    "        tmp.columns = ['hour', 'hit_{}_mean'.format(f)]\n",
    "        tmp['dt'] = t\n",
    "        tmp_df = tmp_df.append(tmp)\n",
    "\n",
    "    data_df = data_df.merge(tmp_df, on=['dt', 'hour'], how='left')\n",
    "\n",
    "data_df = data_df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 30.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 26.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 26.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 25.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# 离散化\n",
    "\n",
    "# 分箱 \n",
    "for f in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']:\n",
    "    data_df[f + '_20_bin'] = pd.cut(data_df[f], 20, duplicates='drop').apply(lambda x: x.left).astype(int) # 分成等宽的20份\n",
    "    data_df[f + '_50_bin'] = pd.cut(data_df[f], 50, duplicates='drop').apply(lambda x: x.left).astype(int)\n",
    "    data_df[f + '_100_bin'] = pd.cut(data_df[f], 100, duplicates='drop').apply(lambda x: x.left).astype(int)\n",
    "    data_df[f + '_200_bin'] = pd.cut(data_df[f], 200, duplicates='drop').apply(lambda x: x.left).astype(int)\n",
    "\n",
    "    \n",
    "# 每个分箱的描述性统计特征\n",
    "\n",
    "for f1 in tqdm(\n",
    "        ['outdoorTemp_20_bin', 'outdoorHum_20_bin', 'outdoorAtmo_20_bin', 'indoorHum_20_bin', 'indoorAtmo_20_bin']):\n",
    "    for f2 in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "\n",
    "        \n",
    "for f1 in tqdm(\n",
    "        ['outdoorTemp_50_bin', 'outdoorHum_50_bin', 'outdoorAtmo_50_bin', 'indoorHum_50_bin', 'indoorAtmo_50_bin']):\n",
    "    for f2 in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "\n",
    "for f1 in tqdm(['outdoorTemp_100_bin', 'outdoorHum_100_bin', 'outdoorAtmo_100_bin', 'indoorHum_100_bin',\n",
    "                'indoorAtmo_100_bin']):\n",
    "    for f2 in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "\n",
    "for f1 in tqdm(['outdoorTemp_200_bin', 'outdoorHum_200_bin', 'outdoorAtmo_200_bin', 'indoorHum_200_bin',\n",
    "                'indoorAtmo_200_bin']):\n",
    "    for f2 in ['outdoorTemp', 'outdoorHum', 'outdoorAtmo', 'indoorHum', 'indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1, f2)] = data_df.groupby([f1])[f2].transform('min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、模型准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model(clf, train_x, train_y, test_x, clf_name, class_num=1):\n",
    "    train = np.zeros((train_x.shape[0], class_num))\n",
    "    test = np.zeros((test_x.shape[0], class_num))\n",
    "\n",
    "    nums = int(train_x.shape[0] * 0.80)\n",
    "\n",
    "    if clf_name in ['sgd', 'ridge']:\n",
    "        print('MinMaxScaler...')\n",
    "        for col in features:\n",
    "            ss = MinMaxScaler() # 归一化\n",
    "            ss.fit(np.vstack([train_x[[col]].values, test_x[[col]].values])) # 按垂直方向叠加（这里就是，同一个特征的值放一列）\n",
    "            train_x[col] = ss.transform(train_x[[col]].values).flatten() # flatten() ，转化为一个array\n",
    "            test_x[col] = ss.transform(test_x[[col]].values).flatten()\n",
    "    \n",
    "    # 前 80%作为训练集，后20%作为验证集\n",
    "    trn_x, trn_y, val_x, val_y = train_x[:nums], train_y[:nums], train_x[nums:], train_y[nums:]\n",
    "\n",
    "    \n",
    "    if clf_name == \"lgb\":\n",
    "        train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "        valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "        data_matrix = clf.Dataset(train_x, label=train_y)\n",
    "\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'mse',\n",
    "            'min_child_weight': 5,\n",
    "            'num_leaves': 2 ** 8,\n",
    "            'feature_fraction': 0.5,\n",
    "            'bagging_fraction': 0.5,\n",
    "            'bagging_freq': 1,\n",
    "            'learning_rate': 0.001,\n",
    "            'seed': 2020\n",
    "        }\n",
    "\n",
    "        model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=500,\n",
    "                          early_stopping_rounds=1000)\n",
    "        model2 = clf.train(params, data_matrix, model.best_iteration) # 使用 bst.best_iteration 最佳迭代\n",
    "        \n",
    "        val_pred = model.predict(val_x, num_iteration=model2.best_iteration).reshape(-1, 1)\n",
    "        test_pred = model.predict(test_x, num_iteration=model2.best_iteration).reshape(-1, 1)  #使用 best_iteration 从最佳迭代中获得预测\n",
    "\n",
    "    if clf_name == \"xgb\":\n",
    "        train_matrix = clf.DMatrix(trn_x, label=trn_y, missing=np.nan)\n",
    "        valid_matrix = clf.DMatrix(val_x, label=val_y, missing=np.nan)\n",
    "        test_matrix = clf.DMatrix(test_x,  missing=np.nan) # label=val_y,\n",
    "        params = {'booster': 'gbtree',\n",
    "                  'eval_metric': 'mae',\n",
    "                  'min_child_weight': 5,\n",
    "                  'max_depth': 8,\n",
    "                  'subsample': 0.5,\n",
    "                  'colsample_bytree': 0.5,\n",
    "                  'eta': 0.001,\n",
    "                  'seed': 2020,\n",
    "                  'nthread': 36,\n",
    "                  'silent': True,\n",
    "                  }\n",
    "\n",
    "        watchlist = [(train_matrix, 'train'), (valid_matrix, 'eval')]\n",
    "\n",
    "        model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=500,\n",
    "                          early_stopping_rounds=1000)\n",
    "        val_pred = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit).reshape(-1, 1)\n",
    "        test_pred = model.predict(test_matrix, ntree_limit=model.best_ntree_limit).reshape(-1, 1)\n",
    "\n",
    "    if clf_name == \"cat\":\n",
    "        params = {'learning_rate': 0.001, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                  'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "\n",
    "        model = clf(iterations=20000, **params)\n",
    "        model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                  cat_features=[], use_best_model=True, verbose=500)\n",
    "\n",
    "        val_pred = model.predict(val_x)\n",
    "        test_pred = model.predict(test_x)\n",
    "\n",
    "    if clf_name == \"sgd\":\n",
    "        params = {\n",
    "            'loss': 'squared_loss',\n",
    "            'penalty': 'l2',\n",
    "            'alpha': 0.00001,\n",
    "            'random_state': 2020,\n",
    "        }\n",
    "        model = SGDRegressor(**params)\n",
    "        model.fit(trn_x, trn_y)\n",
    "        val_pred = model.predict(val_x)\n",
    "        test_pred = model.predict(test_x)\n",
    "\n",
    "    if clf_name == \"ridge\":\n",
    "        params = {\n",
    "            'alpha': 1.0,\n",
    "            'random_state': 2020,\n",
    "        }\n",
    "        model = Ridge(**params)\n",
    "        model.fit(trn_x, trn_y)\n",
    "        val_pred = model.predict(val_x)\n",
    "        test_pred = model.predict(test_x)\n",
    "\n",
    "    print(\"%s_mse_score:\" % clf_name, mean_squared_error(val_y, val_pred))\n",
    "\n",
    "    return val_pred, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(x_train, y_train, x_valid):\n",
    "    lgb_train, lgb_test = single_model(lgb, x_train, y_train, x_valid, \"lgb\", 1)\n",
    "    return lgb_train, lgb_test\n",
    "\n",
    "\n",
    "def xgb_model(x_train, y_train, x_valid):\n",
    "    xgb_train, xgb_test = single_model(xgb, x_train, y_train, x_valid, \"xgb\", 1)\n",
    "    return xgb_train, xgb_test\n",
    "\n",
    "\n",
    "def cat_model(x_train, y_train, x_valid):\n",
    "    cat_train, cat_test = single_model(CatBoostRegressor, x_train, y_train, x_valid, \"cat\", 1)\n",
    "    return cat_train, cat_test\n",
    "\n",
    "\n",
    "def sgd_model(x_train, y_train, x_valid):\n",
    "    sgd_train, sgd_test = single_model(SGDRegressor, x_train, y_train, x_valid, \"sgd\", 1)\n",
    "    return sgd_train, sgd_test\n",
    "\n",
    "\n",
    "def ridge_model(x_train, y_train, x_valid):\n",
    "    ridge_train, ridge_test = single_model(Ridge, x_train, y_train, x_valid, \"ridge\", 1)\n",
    "    return ridge_train, ridge_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备训练集、测试集\n",
    "\n",
    "train_count = train_df.shape[0]\n",
    "train_df = data_df[:train_count].copy().reset_index(drop=True)\n",
    "test_df = data_df[train_count:].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler...\n",
      "ridge_mse_score: 0.044173698683414066\n",
      "MinMaxScaler...\n",
      "sgd_mse_score: 0.06648890255693643\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 72491\n",
      "[LightGBM] [Info] Number of data points in the train set: 19845, number of used features: 670\n",
      "[LightGBM] [Info] Start training from score 0.060368\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[500]\ttraining's l2: 0.245588\tvalid_1's l2: 0.0717825\n",
      "[1000]\ttraining's l2: 0.0988598\tvalid_1's l2: 0.0447101\n",
      "[1500]\ttraining's l2: 0.0428705\tvalid_1's l2: 0.0380899\n",
      "[2000]\ttraining's l2: 0.0209876\tvalid_1's l2: 0.0376698\n",
      "[2500]\ttraining's l2: 0.0120463\tvalid_1's l2: 0.0387404\n",
      "Early stopping, best iteration is:\n",
      "[1795]\ttraining's l2: 0.027635\tvalid_1's l2: 0.0375233\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73060\n",
      "[LightGBM] [Info] Number of data points in the train set: 24807, number of used features: 671\n",
      "[LightGBM] [Info] Start training from score 0.098863\n",
      "lgb_mse_score: 0.03752330100415599\n",
      "[15:18:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mae:0.63988\teval-mae:0.33536\n",
      "[500]\ttrain-mae:0.39926\teval-mae:0.23721\n",
      "[1000]\ttrain-mae:0.25453\teval-mae:0.18827\n",
      "[1500]\ttrain-mae:0.16895\teval-mae:0.16887\n",
      "[2000]\ttrain-mae:0.11943\teval-mae:0.16204\n",
      "[2500]\ttrain-mae:0.09134\teval-mae:0.15933\n",
      "[3000]\ttrain-mae:0.07544\teval-mae:0.15838\n",
      "[3500]\ttrain-mae:0.06627\teval-mae:0.15806\n",
      "[4000]\ttrain-mae:0.06060\teval-mae:0.15785\n",
      "[4500]\ttrain-mae:0.05687\teval-mae:0.15762\n",
      "[5000]\ttrain-mae:0.05425\teval-mae:0.15741\n",
      "[5500]\ttrain-mae:0.05241\teval-mae:0.15731\n",
      "[6000]\ttrain-mae:0.05100\teval-mae:0.15726\n",
      "[6500]\ttrain-mae:0.04984\teval-mae:0.15725\n",
      "[7000]\ttrain-mae:0.04884\teval-mae:0.15721\n",
      "[7500]\ttrain-mae:0.04797\teval-mae:0.15719\n",
      "[8000]\ttrain-mae:0.04714\teval-mae:0.15723\n",
      "[8500]\ttrain-mae:0.04634\teval-mae:0.15725\n",
      "[8525]\ttrain-mae:0.04630\teval-mae:0.15725\n",
      "xgb_mse_score: 0.040180661759955036\n",
      "0:\tlearn: 0.7965894\ttest: 0.4008454\tbest: 0.4008454 (0)\ttotal: 214ms\tremaining: 1h 11m 22s\n",
      "500:\tlearn: 0.5434031\ttest: 0.2911016\tbest: 0.2911016 (500)\ttotal: 9.02s\tremaining: 5m 50s\n",
      "1000:\tlearn: 0.3940601\ttest: 0.2294310\tbest: 0.2294310 (1000)\ttotal: 16.8s\tremaining: 5m 19s\n",
      "1500:\tlearn: 0.3083879\ttest: 0.2017431\tbest: 0.2017431 (1500)\ttotal: 24.5s\tremaining: 5m 1s\n",
      "2000:\tlearn: 0.2604604\ttest: 0.1905721\tbest: 0.1905721 (2000)\ttotal: 32.7s\tremaining: 4m 53s\n",
      "2500:\tlearn: 0.2333026\ttest: 0.1873291\tbest: 0.1873291 (2500)\ttotal: 40.4s\tremaining: 4m 42s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.187220065\n",
      "bestIteration = 2556\n",
      "\n",
      "Shrink model to first 2557 iterations.\n",
      "cat_mse_score: 0.0350513524848524\n"
     ]
    }
   ],
   "source": [
    "drop_columns = [\"time\", \"year\", \"sec\", \"temperature\"]\n",
    "features = train_df[:1].drop(drop_columns, axis=1).columns\n",
    "\n",
    "x_train = train_df[features]\n",
    "x_test = test_df[features]\n",
    "\n",
    "# 以 室内外温差 作为label\n",
    "y_train = train_df['temperature'].values - train_df['outdoorTemp'].values  \n",
    "\n",
    "lr_train, lr_test = ridge_model(x_train, y_train, x_test)\n",
    "\n",
    "sgd_train, sgd_test = sgd_model(x_train, y_train, x_test)\n",
    "\n",
    "lgb_train, lgb_test = lgb_model(x_train, y_train, x_test)\n",
    "\n",
    "xgb_train, xgb_test = xgb_model(x_train, y_train, x_test)\n",
    "\n",
    "cat_train, cat_test = cat_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、模型结果取均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = (lr_train + sgd_train + lgb_train[:, 0] + xgb_train[:, 0] + cat_train) / 5\n",
    "test_pred = (lr_test + sgd_test + lgb_test[:, 0] + xgb_test[:, 0] + cat_test) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(test_df['time']) \n",
    "sub[\"temperature\"] = test_pred + test_df['outdoorTemp'].values \n",
    "sub.to_csv('sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
